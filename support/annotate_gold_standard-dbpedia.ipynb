{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tool is used to annotate links. The tool is configured to annotate fb15k and dbpedia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, specify the paths of the test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy\n",
    "import torch\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, Layout, ButtonStyle\n",
    "from IPython.display import Markdown\n",
    "import requests\n",
    "from time import sleep\n",
    "import random\n",
    "import datetime\n",
    "import os\n",
    "import urllib\n",
    "from functools import cmp_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder = '/home/jurbani/data2/binary-embeddings/fb15k237/'\n",
    "#'/Users/jacopo/Desktop/binary-embeddings/fb15k237/'\n",
    "# The file where all the annotations are stored\n",
    "annotations_file = main_folder + '/annotations/gold-annotations.json'\n",
    "testdata_raw_path = '/home/uji300/OpenKE/benchmarks/fb15k237/test2id.txt'\n",
    "#'/Users/jacopo/Documents/projects/OpenKE-unmesh/benchmarks/fb15k237/test2id.txt'\n",
    "unmesh_annotations = '/misc/annotations_transe_unmesh.json'\n",
    "annotator = 'U'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata_folder = main_folder + 'answers/'\n",
    "testdata_transe_path_head = testdata_folder + 'fb15k237-answers-transe-test-10-head.pkl'\n",
    "testdata_transe_path_tail = testdata_folder + 'fb15k237-answers-transe-test-10-tail.pkl'\n",
    "testdata_complex_path_head = testdata_folder + 'fb15k237-answers-complex-test-10-head.pkl'\n",
    "testdata_complex_path_tail = testdata_folder + 'fb15k237-answers-complex-test-10-tail.pkl'\n",
    "testdata_rotate_path_head = testdata_folder + 'fb15k237-answers-rotate-test-10-head.pkl'\n",
    "testdata_rotate_path_tail = testdata_folder + 'fb15k237-answers-rotate-test-10-tail.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_labels_path = '/home/uji300/OpenKE/benchmarks/fb15k237/entity2id.txt'\n",
    "#'/Users/jacopo/Documents/projects/OpenKE-unmesh/benchmarks/fb15k237/entity2id.txt'\n",
    "\n",
    "rel_labels_path = '/home/uji300/OpenKE/benchmarks/fb15k237/relation2id.txt'\n",
    "#'/Users/jacopo/Documents/projects/OpenKE-unmesh/benchmarks/fb15k237/relation2id.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_labels = {}\n",
    "with open(ent_labels_path, 'rt') as f:\n",
    "    nents = int(f.readline())\n",
    "    for line in f:\n",
    "        tkns = line.split('\\t')\n",
    "        ent_labels[int(tkns[1])] = tkns[0]\n",
    "    assert(len(ent_labels) == nents)\n",
    "rel_labels = {}\n",
    "with open(rel_labels_path, 'rt') as f:\n",
    "    nrels = int(f.readline())\n",
    "    for line in f:\n",
    "        tkns = line.split('\\t')\n",
    "        rel_labels[int(tkns[1])] = tkns[0]\n",
    "    assert(len(rel_labels) == nrels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the raw test triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test_triples = set()\n",
    "with open(testdata_raw_path, 'rt') as f:\n",
    "    nfacts = int(f.readline())\n",
    "    for l in f:\n",
    "        tkns = l.split(' ')\n",
    "        h = int(tkns[0])\n",
    "        t = int(tkns[1])\n",
    "        r = int(tkns[2])\n",
    "        raw_test_triples.add((h, t, r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(testdata_transe_path_head, 'rb') as fin:\n",
    "    testdata_transe_head = pkl.load(fin) # json.load(open(testdata_transe_path, 'rt'))\n",
    "with open(testdata_transe_path_tail, 'rb') as fin:\n",
    "    testdata_transe_tail = pkl.load(fin)\n",
    "with open(testdata_complex_path_head, 'rb') as fin:\n",
    "    testdata_complex_head = pkl.load(fin) # json.load(open(testdata_complex_path, 'rt'))\n",
    "with open(testdata_complex_path_tail, 'rb') as fin:\n",
    "    testdata_complex_tail = pkl.load(fin)\n",
    "with open(testdata_rotate_path_head, 'rb') as fin:\n",
    "    testdata_rotate_head = pkl.load(fin) # json.load(open(testdata_rotate_path, 'rt'))\n",
    "with open(testdata_rotate_path_tail, 'rb') as fin:\n",
    "    testdata_rotate_tail = pkl.load(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute all the head and tail queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "queries_tail = {}\n",
    "for name, testset in [(\"transe\", testdata_transe_tail), (\"complex\", testdata_complex_tail), (\"rotate\", testdata_rotate_tail)]:\n",
    "    for t in testset:\n",
    "        ent = t['ent']\n",
    "        rel = t['rel']\n",
    "        if (ent, rel) in queries_tail:\n",
    "            answers = queries_tail[(ent, rel)]\n",
    "            if name not in answers:\n",
    "                answers[name] = t['answers_fil']\n",
    "        else:\n",
    "            a = { name : t['answers_fil'] }            \n",
    "            queries_tail[(ent, rel)] = a\n",
    "\n",
    "queries_head = {}\n",
    "for name, testset in [(\"transe\", testdata_transe_head), (\"complex\", testdata_complex_head), (\"rotate\", testdata_rotate_head)]:\n",
    "    for t in testset:\n",
    "        ent = t['ent']\n",
    "        rel = t['rel']    \n",
    "        if (ent, rel) in queries_head:\n",
    "            answers = queries_head[(ent, rel)]\n",
    "            if name not in answers:\n",
    "                answers[name] = t['answers_fil']\n",
    "        else:\n",
    "            a = { name : t['answers_fil'] }           \n",
    "            queries_head[(ent, rel)] = a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy all the queries into a single list. Also, load all the queries annotated by Unmesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Queries: 22850\n",
      "# Queries annotated by Unmesh: 410\n"
     ]
    }
   ],
   "source": [
    "queries = []\n",
    "counter = 0\n",
    "for q, a in queries_head.items():\n",
    "    queries.append({'id': counter, 'type': 0, 'ent' : q[0], 'rel' : q[1], 'answers' : a})\n",
    "    counter += 1    \n",
    "for q, a in queries_tail.items():\n",
    "    queries.append({'id': counter, 'type': 1, 'ent' : q[0], 'rel' : q[1], 'answers' : a})    \n",
    "    counter += 1\n",
    "unmesh_queries = json.load(open(main_folder + '/' + unmesh_annotations))\n",
    "unmesh_queries_by_query_id = {}\n",
    "for q in unmesh_queries:\n",
    "    query = q['query']\n",
    "    # Give the same ID used for all queries\n",
    "    found = False\n",
    "    for q2 in queries:\n",
    "        if q2['type'] == query['type'] and q2['ent'] == query['ent'] and q2['rel'] == query['rel']:\n",
    "            found = True\n",
    "            query['id'] = q2['id']\n",
    "            # Compare the annotated answers by Unmesh and the total numbers.\n",
    "            unmesh_answers = q['annotated_answers']\n",
    "            total_answers = q2['answers']\n",
    "            col_answers = set()\n",
    "            for method, ans in total_answers.items():\n",
    "                for a in ans:\n",
    "                    col_answers.add(a)\n",
    "            overlap = 0\n",
    "            for a in unmesh_answers:\n",
    "                if a['entity_id'] in col_answers:\n",
    "                    overlap += 1\n",
    "            q['not_annotated_answers'] = len(col_answers) - overlap\n",
    "            assert(len(col_answers) - overlap >= 0)\n",
    "            break    \n",
    "    assert(found == True)\n",
    "    unmesh_queries_by_query_id[query['id']] = q\n",
    "#random.shuffle(unmesh_queries)\n",
    "unmesh_queries = sorted(unmesh_queries, key=cmp_to_key(lambda i1, i2: i1['not_annotated_answers'] - i2['not_annotated_answers']))\n",
    "\n",
    "print(\"# Queries:\", len(queries))\n",
    "print(\"# Queries annotated by Unmesh:\", len(unmesh_queries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading annotations from file /home/jurbani/data2/binary-embeddings/fb15k237//annotations/gold-annotations.json\n",
      "# Processed Queries: 207\n"
     ]
    }
   ],
   "source": [
    "out = widgets.Output(layout={'padding': '5px', 'border': '1px solid black'})\n",
    "array_answers = []\n",
    "valid_annotations = True\n",
    "current_query_id = None\n",
    "processed_queries = {}\n",
    "if os.path.exists(annotations_file):\n",
    "    print(\"Loading annotations from file\", annotations_file)\n",
    "    processed_queries = json.load(open(annotations_file, 'rt'))\n",
    "print(\"# Processed Queries:\", len(processed_queries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def pick_next_query():\n",
    "    global current_query_id\n",
    "    global unmesh_queries\n",
    "    if len(processed_queries) < len(queries):\n",
    "        # First select the first query by Unmesh that has not yet been processed\n",
    "        found = False\n",
    "        for i, q in enumerate(unmesh_queries):\n",
    "            if q['query']['id'] not in processed_queries:\n",
    "                found = True\n",
    "                idx = q['query']['id']\n",
    "                break\n",
    "        # Select a random query that is not yet processed\n",
    "        while not found:\n",
    "            idx = random.randint(0, len(queries) - 1)\n",
    "            if idx not in processed_queries:\n",
    "                break\n",
    "        current_query_id = idx\n",
    "        return True        \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def on_change_checkbox(b):\n",
    "    owner = b['owner']\n",
    "    desc = owner.description\n",
    "    id_answer = int(owner.description[0:desc.find('.')])\n",
    "    value = b['new']\n",
    "    if value is True:\n",
    "        array_answers[id_answer]['checked']= True\n",
    "    else:\n",
    "        array_answers[id_answer]['checked']= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def dump_on_file():\n",
    "    # First check if the file exist\n",
    "    if os.path.exists(annotations_file):\n",
    "        now = str(datetime.datetime.now())\n",
    "        old_file = annotations_file + '-' + now\n",
    "        os.rename(annotations_file, old_file)\n",
    "    json.dump(processed_queries, open(annotations_file, 'wt'), indent = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def on_click_button(b):\n",
    "    global processed_queries\n",
    "    global current_query_id\n",
    "    global valid_annotations\n",
    "    \n",
    "    out.clear_output()\n",
    "    # Store the annotation\n",
    "    query = queries[current_query_id]\n",
    "    print(array_answers)\n",
    "    processed_queries[current_query_id] = {'query' : query, 'valid_annotations' : valid_annotations, 'annotated_answers' : array_answers, 'annotator' : annotator, 'date': str(datetime.datetime.now())}\n",
    "    dump_on_file()\n",
    "    \n",
    "    # Move to the next query\n",
    "    with out:\n",
    "        ok = pick_next_query()\n",
    "        if ok is not None:\n",
    "            query = queries[current_query_id]\n",
    "            print_query_answers(query['id'], query['type'], query['ent'], query['rel'], query['answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def on_click_skip_button(b):\n",
    "    global valid_annotations\n",
    "    valid_annotations = False\n",
    "    on_click_button(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def print_query_answers(query_id, typ, ent, rel, answers):\n",
    "    global processed_queries\n",
    "    global array_answers\n",
    "    global valid_annotations\n",
    "    global unmesh_queries_by_query_id\n",
    "    valid_annotations = True\n",
    "    n_skipped = 0\n",
    "    n_ok = 0\n",
    "    n_annotated_answers = 0\n",
    "    n_tail_queries = 0\n",
    "    n_head_queries = 0\n",
    "    for _, q in processed_queries.items():\n",
    "        if q['valid_annotations']:\n",
    "            n_ok += 1\n",
    "            n_annotated_answers += len(q['annotated_answers'])\n",
    "            if q['query']['type'] == 1:\n",
    "                n_tail_queries += 1\n",
    "            else:\n",
    "                n_head_queries += 1\n",
    "        else:\n",
    "            n_skipped += 1\n",
    "    print(\"Processed queries: {} Skipped: {} Ok: {} Head: {} Tail: {}\".format(len(processed_queries), n_skipped, n_ok, n_head_queries, n_tail_queries))\n",
    "    print(\"Annnotated answers: {}\\n\".format(n_annotated_answers))\n",
    "    typ_str = 'HEAD'\n",
    "    if typ == 1:\n",
    "        typ_str = 'TAIL'\n",
    "    display(Markdown(\"***Query #{} Type {}***\".format(query_id, typ_str)))\n",
    "    lbl, link_wikidata = retrieve_wikidata_label(ent_labels[ent])\n",
    "    ent_str = '[' + lbl + ' ' + link_wikidata + ' (' + ent_labels[ent] + ')]'   \n",
    "    if typ == 0:\n",
    "        print(\"?\", rel_labels[rel], ent_str)\n",
    "    else:\n",
    "        print(ent_str, rel_labels[rel], \"?\")\n",
    "    #print(\"\\n\")\n",
    "    \n",
    "    unmesh_annotations = None\n",
    "    if query_id in unmesh_queries_by_query_id:\n",
    "        print(\"\\nThis query was previously annotated by Unmesh\")\n",
    "        unmesh_annotations = unmesh_queries_by_query_id[query_id]['annotated_answers']\n",
    "\n",
    "    lbl_google = urllib.parse.urlencode({\"q\" : lbl})\n",
    "    google_link = \"https://www.google.com/search?hl=en&\" + lbl_google\n",
    "    display(Markdown(\"***Search on Google:*** {}\".format(google_link)))\n",
    "    print(\"\\nAnswers (striked answers are the ones that are already annotated):\")\n",
    "    array_answers = []\n",
    "    for method, answers_method in answers.items():\n",
    "        for i, a in enumerate(answers_method):\n",
    "            # Should I add it?\n",
    "            found = False\n",
    "            for j, array_answer in enumerate(array_answers):\n",
    "                if array_answer['entity_id'] == a:\n",
    "                    found = True\n",
    "                    array_answer['methods'].append(method)\n",
    "                    break                    \n",
    "            if not found:\n",
    "                # Is the answer known to be true?\n",
    "                found = False\n",
    "                if typ == 0 and (a, ent, rel) in raw_test_triples:\n",
    "                    found = True\n",
    "                if typ == 1 and (ent, a, rel) in raw_test_triples:\n",
    "                    found = True\n",
    "                if found:\n",
    "                    array_answers.append({'entity_id' : a, 'checked' : True, 'methods': [method], 'enabled' : False})\n",
    "                else:\n",
    "                    if unmesh_annotations is not None:\n",
    "                        # Search if the entity is mentioned\n",
    "                        for unmesh_annotation in unmesh_annotations:\n",
    "                            if unmesh_annotation['entity_id'] == a:\n",
    "                                found = True\n",
    "                                if unmesh_annotation['checked'] == True:\n",
    "                                    array_answers.append({'entity_id' : a, 'checked' : True, 'methods': [method], 'enabled' : False})\n",
    "                                else:\n",
    "                                    array_answers.append({'entity_id' : a, 'checked' : False, 'methods': [method], 'enabled' : False})\n",
    "                                break                                \n",
    "                    if not found:\n",
    "                        array_answers.append({'entity_id' : a, 'checked' : False, 'methods': [method], 'enabled' : True})\n",
    "                        \n",
    "    for i, a in enumerate(array_answers):\n",
    "        sleep(1) # Some sleeping is necessary for wikidata\n",
    "        lbl, link_wikidata = retrieve_wikidata_label(ent_labels[a['entity_id']])\n",
    "        a_str = '[' + lbl + ' <a href=' + link_wikidata + '>' + link_wikidata + '</a> (' + ent_labels[a['entity_id']] + ')]'\n",
    "        desc = \"{}. {} ({}) methods={}\".format(i, a_str, a['entity_id'], a['methods'])\n",
    "        if a['enabled'] == False:\n",
    "            box = widgets.Checkbox(a['checked'], id=len(array_answers), description=\"<strike>\" + desc + \"</strike>\", layout=Layout(width='2000px', height='20px'), indent=False, disabled=True)\n",
    "        else:\n",
    "            box = widgets.Checkbox(False, id=len(array_answers), description=desc, layout=Layout(width='2000px', height='20px'), indent=False)\n",
    "        box.observe(on_change_checkbox, names=\"value\")\n",
    "        display(box)\n",
    "        if a['enabled'] == True:\n",
    "            lbl_google = urllib.parse.urlencode({\"q\" : lbl})\n",
    "            google_link = \"https://www.google.com/search?hl=en&\" + lbl_google\n",
    "            lbl_wikipedia = urllib.parse.urlencode({\"search\" : lbl})\n",
    "            wikipedia_link = \"https://en.wikipedia.org/w/index.php?\" + lbl_wikipedia\n",
    "            display(Markdown(\"&ensp;&ensp;&ensp;{} {}\".format(google_link, wikipedia_link)))\n",
    "\n",
    "    print(\"\\n\")\n",
    "    display(Markdown(\"***Known answers from the testset:***\"))\n",
    "    known_answers = []\n",
    "    for triple in raw_test_triples: #(h,t,r)\n",
    "        if triple[2] == rel:\n",
    "            if typ == 0 and triple[1] == ent:\n",
    "                known_answers.append(triple[0])\n",
    "            if typ == 1 and triple[0] == ent:\n",
    "                known_answers.append(triple[1])\n",
    "    assert(len(known_answers) > 0)\n",
    "    for known_answer in known_answers:\n",
    "        sleep(1) # Some sleeping is necessary for wikidata\n",
    "        lbl, link_wikidata = retrieve_wikidata_label(ent_labels[known_answer])\n",
    "        a_str = '[' + lbl + ' ' + link_wikidata + ' (' + ent_labels[known_answer] + ')]'   \n",
    "        desc = \"{} ({})\".format(a_str, known_answer)\n",
    "        print(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def retrieve_wikidata_label(e):\n",
    "    # Query Wikidata\n",
    "    try:\n",
    "        query = 'PREFIX wd: <http://www.wikidata.org/entity/> ' + 'PREFIX wdt: <http://www.wikidata.org/prop/direct/> ' + \"SELECT ?x ?xLabel WHERE { ?x wdt:P646 \\\"\" + e + \"\\\"; SERVICE wikibase:label { bd:serviceParam wikibase:language \\\"[AUTO_LANGUAGE],en\\\". } }\"\n",
    "        r = requests.get('https://query.wikidata.org/bigdata/namespace/wdq/sparql', params = {'format': 'json', 'query': query})\n",
    "        if r:\n",
    "            r = r.json()\n",
    "            results = r['results']\n",
    "            bindings = results['bindings']\n",
    "            # Take the first\n",
    "            binding = bindings[0]\n",
    "            value = binding['x']['value']\n",
    "            lbl = binding['xLabel']['value']\n",
    "            return lbl, value\n",
    "    except:\n",
    "        pass\n",
    "    return 'None', 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the annotation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d2931cfdcc4850a25889afd014618a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='1px solid black', padding='5px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f440881ce89947dcbf25bfb8fbf9ce5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Submit', style=ButtonStyle(font_weight='bf'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "449ae2849e7b48c7bd84c36e2c57cae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Skip', style=ButtonStyle(font_weight='bf'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out.clear_output()\n",
    "ok = pick_next_query()\n",
    "with out:    \n",
    "    if ok is not None:\n",
    "        query = queries[current_query_id]\n",
    "        print_query_answers(query['id'], query['type'], query['ent'], query['rel'], query['answers'])\n",
    "b = widgets.Button(description='Submit', style=ButtonStyle(font_weight='bf'))\n",
    "b.on_click(on_click_button)\n",
    "b_skip = widgets.Button(description='Skip', style=ButtonStyle(font_weight='bf'))\n",
    "b_skip.on_click(on_click_skip_button)\n",
    "display(out)\n",
    "display(b)\n",
    "display(b_skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
